1) Generate an explain plan for a complex query

  ' V$SQL_PLAN ' view will contain the execution plan for the sql statement that is recently executed.
  The  ' PLAN_TABLE ' is automatically created as a global temporary table to hold the output of an EXPLAIN PLAN     statement for all users.
  

  //utlxplan.sql  script has the plan table stored
  @C:\oraclexe\app\oracle\product\10.2.0\server\RDBMS\ADMIN\utlxplan.sql

  // query for getting explain plan for a sql query
  EXPLAIN PLAN FOR
  SELECT bookname FROM books;

output:
Explained.

2) Check if there are any chained rows
  ?Tables with RAW and LONG RAW columns are historically more prone to ending up with  chained rows
 ?Super-wide tables also end up with chained rows.  Tables with in excess of 255 columns end up with chained rows.  These wide tables get broken up into pieces.  As a result, there will be data on two or more blocks that has to be chained together.  

  The chain.sql script to detect tables with migrated/chained rows.

   //identify migrated/chained rows in tables  that contain RAW or LONG RAW columns.

   variable monitored_sid number;

begin

SELECT 
   sid into :monitored_sid 
 from 
   v$session 
where 
   audsid=USERENV('SESSIONID');

end;
 /

select 
   b.value "table fetch continued rows"
from
   v$sesstat b
where 
   b.SID = :monitored_sid
and 
   b.statistic# = 
   (select 
      statistic# 
    from 
      v$statname  
    where 
      name='table fetch continued row');

//A report of migrated/chained rows in tables that contain RAW columns
set heading off;
select 'Tables with migrated/chained rows that contain RAW columns.' from dual;
set heading on;
 
select
   owner c1,
   table_name c2,
   pct_free c3,
   pct_used c4,
   avg_row_len c5, 
   num_rows c6,
   chain_cnt c7,
   chain_cnt/num_rows c8
from dba_tables
where
owner not in ('SYS','SYSTEM')
and
table_name in
 (select table_name from dba_tab_columns
where
 data_type in ('RAW','LONG RAW','CLOB','BLOB','NCLOB')
 )
and
chain_cnt > 0
order by chain_cnt desc
;



3) Backup data of a particular table / schema
   a. Go to Bin directory and Click on "RMAN".It is standard feature in Oracle for back up
   b.In BIN folder you would also find IMPDP and EXPDP. using these two you can take up of a)Individual tables          b)Schema c)Whole database 
    

   Another Solution:use "imp" and "exp" present in BIN to take back up
   a)Male a batch file using expdp command of oracle 
   b)create a directory using sql command and set the target area for taking back up 
   c)save the batch file d)use WINDOWS SCHEDULER to schedule your routined back up
	

4) Bulk load data into a table from file
 // bulk insert into oracle 

 begin
    for r in (select rownum rn, t.* from foo t) loop
        insert into bar (A,B,C) values (r.A,r.B,r.C);
        if mod(rn,1000)=0 then
            commit;
        end if;
    end;
    commit;
end;

// using cursor 
DECLARE
   CURSOR C1 IS SELECT * FROM FOO;
BEGIN
   FOR C1_REC IN C1 LOOP
   INSERT INTO BAR(A,
                B,
                C)
          VALUES(C1.A,
                 C1.B,
                 C1.C);
   END LOOP;
END

// bulk update
UPDATE table1 SET table1.value = (SELECT table2.CODE
                                  FROM table2 
                                  WHERE table1.value = table2.DESC)
WHERE table1.UPDATETYPE='blah'
AND EXISTS (SELECT table2.CODE
            FROM table2 
            WHERE table1.value = table2.DESC);



5)Execute bulk delete and truncate operation
  //  for bulk delete 
 DECLARE 
 TYPE tt_delete IS TABLE OF ROWID;
 t_delete tt_delete;
 CURSOR c_delete IS
 SELECT ROWID
 FROM test_tbl
 WHERE test_col < 6;
 l_delete_buffer PLS_INTEGER := 5000;
 BEGIN
 OPEN c_delete;
 LOOP
 FETCH c_delete BULK COLLECT 
 INTO t_delete LIMIT l_delete_buffer;
 FORALL i IN 1..t_delete.COUNT
 DELETE test_tbl
 WHERE ROWID = t_delete (i);
 EXIT WHEN c_delete%NOTFOUND;
 COMMIT;
 END LOOP;
 CLOSE c_delete;
 END;

// bulk truncate 
CREATE TABLE test_tbl_temp AS
SELECT * 
  FROM TEST_TBL
 WHERE 
MONTHS_BETWEEN(SYSDATE, TO_DATE(YRMO_NBR||'01','YYYYMMDD')) <= 38;

TRUNCATE TABLE test_tbl;

INSERT /*+ APPEND +/ INTO test_tbl
SELECT *
  FROM test_tbl_temp;




6) Create a public/shared database link

using CREATE DATABASE LINK statement`
 // public link
 CREATE PUBLIC DATABASE LINK remote 
   USING 'remote';
//Defining a Fixed-User Database Link:
CREATE DATABASE LINK local 
   CONNECT TO hr IDENTIFIED BY hr
   USING 'local';

//Defining a CURRENT_USER Database Link:
CREATE DATABASE LINK remote.us.oracle.com
   CONNECT TO CURRENT_USER
   USING 'remote';

The user who issues this statement must be a global user registered with the LDAP directory service.

// views :ALL_DB_LINKS, DBA_DB_LINKS, and USER_DB_LINKS

7) Execute copy command to copy table data from remote location

     
   syntax:COPY {FROM database | TO database | FROM database TO database} {APPEND|CREATE|INSERT|REPLACE} destination_table [(column, column, column, ...)] USING query


where database has the following syntax:

username[/password]@connect_identifier


COPY FROM HR@HQ TO JOHN@WEST -
REPLACE WESTEMPLOYEES -
USING SELECT * FROM EMPLOYEES


// Copying Data from One Database to Another


COPY FROM HR@BOSTONDB -
TO TODD@CHICAGODB -
CREATE NEWDEPT (DEPARTMENT_ID, DEPARTMENT_NAME, CITY) -
USING SELECT * FROM EMP_DETAILS_VIEW


//Copying from a Remote Database to Your Local Database Using CREATE

COPY FROM HR@BOSTONDB -
CREATE EMPCOPY -
USING SELECT * FROM HR
